[{"content":"def rle_decode(mask_rle, shape): \u0026#39;\u0026#39;\u0026#39; mask_rle: run-length as string formated (start length) shape: (height,width) of array to return Returns numpy array, 1 - mask, 0 - background \u0026#39;\u0026#39;\u0026#39; s = mask_rle.split() starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])] starts -= 1 ends = starts + lengths img = np.zeros(shape[0]*shape[1], dtype=np.uint8) for lo, hi in zip(starts, ends): img[lo:hi] = 1 return img.reshape(shape) def rle_encode(img): \u0026#39;\u0026#39;\u0026#39; img: numpy array, 1 - mask, 0 - background Returns run length as string formated \u0026#39;\u0026#39;\u0026#39; pixels = img.flatten() pixels = np.concatenate([[0], pixels, [0]]) runs = np.where(pixels[1:] != pixels[:-1])[0] + 1 runs[1::2] -= runs[::2] return \u0026#39; \u0026#39;.join(str(x) for x in runs) def flatten_l_o_l(nested_list): \u0026#34;\u0026#34;\u0026#34; Flatten a list of lists \u0026#34;\u0026#34;\u0026#34; return [item for sublist in nested_list for item in sublist] def load_json_to_dict(json_path): \u0026#34;\u0026#34;\u0026#34; tbd \u0026#34;\u0026#34;\u0026#34; with open(json_path) as json_file: data = json.load(json_file) return data def get_img_and_mask(img_path, annotation, width, height): \u0026#34;\u0026#34;\u0026#34; Capture the relevant image array as well as the image mask \u0026#34;\u0026#34;\u0026#34; img_mask = np.zeros((height, width), dtype=np.uint8) for i, annot in enumerate(annotation): img_mask = np.where(rle_decode(annot, (height, width))!=0, i, img_mask) img = cv2.imread(img_path)[..., ::-1] return img[..., 0], img_mask def plot_img_and_mask(img, mask, invert_img=True, boost_contrast=True): \u0026#34;\u0026#34;\u0026#34; Function to take an image and the corresponding mask and plot Args: img (np.arr): 1 channel np arr representing the image of cellular structures mask (np.arr): 1 channel np arr representing the instance masks (incrementing by one) invert_img (bool, optional): Whether or not to invert the base image boost_contrast (bool, optional): Whether or not to boost contrast of the base image Returns: None; Plots the two arrays and overlays them to create a merged image \u0026#34;\u0026#34;\u0026#34; plt.figure(figsize=(20,10)) plt.subplot(1,3,1) _img = np.tile(np.expand_dims(img, axis=-1), 3) # Flip black--\u0026gt;white ... white--\u0026gt;black if invert_img: _img = _img.max()-_img if boost_contrast: _img = np.asarray(ImageEnhance.Contrast(Image.fromarray(_img)).enhance(16)) plt.imshow(_img) plt.axis(False) plt.title(\u0026#34;Cell Image\u0026#34;, fontweight=\u0026#34;bold\u0026#34;) plt.subplot(1,3,2) _mask = np.zeros_like(_img) _mask[..., 0] = mask plt.imshow(mask, cmap=\u0026#39;rainbow\u0026#39;) plt.axis(False) plt.title(\u0026#34;Instance Segmentation Mask\u0026#34;, fontweight=\u0026#34;bold\u0026#34;) merged = cv2.addWeighted(_img, 0.75, np.clip(_mask, 0, 1)*255, 0.25, 0.0,) plt.subplot(1,3,3) plt.imshow(merged) plt.axis(False) plt.title(\u0026#34;Cell Image w/ Instance Segmentation Mask Overlay\u0026#34;, fontweight=\u0026#34;bold\u0026#34;) plt.tight_layout() plt.show() def polygonFromMask(maskedArr, idx): # adapted from https://github.com/hazirbas/coco-json-converter/blob/master/generate_coco_json.py contours, _ = cv2.findContours(maskedArr, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE) segmentation = [] valid_poly = 0 for contour in contours: # Valid polygons have \u0026gt;= 6 coordinates (3 points) if contour.size \u0026gt;= 6: segmentation.append(contour.astype(float).flatten().tolist()) valid_poly += 1 if valid_poly == 0: raise ValueError(idx) return [segmentation] ","permalink":"https://eb1ta1.github.io/posts/ayusa/","summary":"def rle_decode(mask_rle, shape): \u0026#39;\u0026#39;\u0026#39; mask_rle: run-length as string formated (start length) shape: (height,width) of array to return Returns numpy array, 1 - mask, 0 - background \u0026#39;\u0026#39;\u0026#39; s = mask_rle.split() starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])] starts -= 1 ends = starts + lengths img = np.zeros(shape[0]*shape[1], dtype=np.uint8) for lo, hi in zip(starts, ends): img[lo:hi] = 1 return img.reshape(shape) def rle_encode(img): \u0026#39;\u0026#39;\u0026#39; img: numpy array, 1 - mask, 0 - background Returns run length as string formated \u0026#39;\u0026#39;\u0026#39; pixels = img.","title":"HugoでWebフォント人類社会のすべての構成員の固有の尊厳と平等で譲ることのできない権利とを承認することは機械学習"}]